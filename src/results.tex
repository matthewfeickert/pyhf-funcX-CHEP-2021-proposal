\section{Scaling of Statistical Inference}\label{sec:results}
%
Using the \funcX{} configuration deployed on RIVER described in~\Cref{subsec:FaaS_analysis_facilities}, \funcX{} is able to receive posted JSON serializations of the \pyhf{} pallet containing the background workspace and signal patches downloaded from HEPData~\cite{ATLAS_SUSY_1Lbb_pallet}, start \funcX{} worker nodes, send patched workspaces to each worker, fit the workspace and return the results with a user wall time of under 3 minutes.
As this wall time includes data transfer to and from the user's machine and RIVER, and worker node orchestration time, the time required for inference alone is even smaller.
Example typical run output and performance can be seen in~\Cref{lst:funcX_demo_output}.
The timing results, using \pyhf{}'s NumPy backend and SciPy optimizer, over multiple trials for Ref.~\cite{ATLAS_SUSY_1Lbb_pallet}, along with the results from additional analyses~\cite{SUSY-2018-09,SUSY-2018-04} that have openly published probability models as \pyhf{} pallets on HEPData~\cite{ATLAS_SUSY_SS3L_pallet,ATLAS_SUSY_staus_pallet}, are summarized in~\Cref{table:performance} and compared to the fit time for all patches on a single node.
All code used in these studies is publicly available on GitHub at Ref.~\cite{study_code}.

\input{src/tables/performance_table.tex}

These results are not fundamental limits of the performance of the software and are meant as preliminary tests of scaling on heterogeneous architecture.
For comparison, on a local system with an AMD Ryzen 9 3900X processor (12 cores 3.8GHz) and 2 x 32GB DDR4-2400 Memory (64 GB) the fitting results for the 125 signal patches of Ref.~\cite{ATLAS_SUSY_1Lbb_pallet} on a single core were obtained in 1672 seconds.
