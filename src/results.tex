\section{Scaling of Statistical Inference}\label{sec:results}
%
Using the \funcX{} configuration deployed on RIVER described in~\Cref{subsec:FaaS_analysis_facilities}, \funcX{} is able to receive posted JSON serializations of the \pyhf{} pallet containing the background workspace and signal patches downloaded from HEPData~\cite{ATLAS_SUSY_1Lbb_pallet}, start \funcX{} worker nodes, send patched workspaces to each worker, fit the workspace and return the results with a user wall time of under 3 minutes.
As this wall time includes data transfer to and from the user's machine and RIVER, and worker node orchestration time, the time required for inference alone is even smaller.
Example typical run output and performance can be seen in~\Cref{lst:funcX_demo_output}.
The timing results, using \pyhf{}'s NumPy backend and SciPy optimizer, over multiple trials for Ref.~\cite{ATLAS_SUSY_1Lbb_pallet}, along with the results from additional analyses~\cite{SUSY-2018-09,SUSY-2018-04} that have openly published probability models as \pyhf{} pallets on HEPData~\cite{ATLAS_SUSY_SS3L_pallet,ATLAS_SUSY_staus_pallet}, are summarized in~\Cref{table:performance} and compared to the fit time for all patches on a single node.
All code used in these studies is publicly available on GitHub at Ref.~\cite{study_code}.

\input{src/tables/performance_table.tex}

\TODO{Write things that make sense here expalinging RIVER vs. Beast and funcX batch API results.}
These results are not fundamental limitations of the software as preliminary tests of scaling on different hardware.
