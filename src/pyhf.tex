\subsection{\pyhf{}}\label{subsec:pyhf}

For measurements in HEP based on binned data (histograms), the \HiFa{}~\cite{Cranmer:1456844} family of statistical models has been widely used for likelihood construction in Standard Model measurements (e.g. Refs.~\cite{HIGG-2013-02,Aaij:2015sqa}) as well as searches for new physics (e.g. Ref.~\cite{SUSY-2016-10}) and reinterpretation studies (e.g. Ref.~\cite{Alguero:2020grj}).
\pyhf{} is a pure-Python implementation of the \HiFa{} statistical model for multi-bin histogram-based analysis.
\pyhf{}'s interval estimation is computed through either the use of the asymptotic formulas of Ref.~\cite{Cowan:2010js} or empirically through pseudoexperiments (``toys'' in HEP parlance).
Through adoption of open source ``tensor'' computational Python libraries (i.e. NumPy, TensorFlow, PyTorch, and JAX), \pyhf{} is able to leverage tensor calculations to outperform the traditional C++ implementations of \HiFa{} on data from real LHC analyses.
\pyhf{} can additionally leverage automatic differentiation and hardware acceleration from the tensor libraries that support them to further accelerate fitting.
Through use of JSON to provide a declarative plain-text serialisation for describing \HiFa{}-based likelihoods~\cite{ATL-PHYS-PUB-2019-029} --- well suited for reinterpretation and long-term preservation in analysis data repositories such as HEPData~\cite{Maguire:2017ypu} --- \pyhf{} has also become a widely used tool across experiment and theory.
Given its lightweight core dependencies and wide distribution through The Python Package Index (PyPI), Conda-forge, and CernVM File System (CernVM-FS) it is easily installable on a wide variety of platforms, including Linux containers.
Minimally sized Docker images containing stable releases of \pyhf{} are also distributed through Docker Hub.
